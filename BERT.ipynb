{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5szn7axNlC5qgLKvlJocy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejihoon6065/BERT_stock_forecasting/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZNsmESw7kxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "b0d1dd8c-8471-45f0-f92e-7ccaedbf1853"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep 17 07:20:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-9L9XIB4isc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "b5dccb91-6442-488a-b170-da3bd5d6d8f2"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 8.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.59)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.59 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.59)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.59->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.59->boto3->pytorch-transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4b9acebc7ee7882a3750aecdbee8f973340b9a8a1fd59d4f67b00e16aa66867c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTeuyf6A4khA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Dkbpcv5HTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "89c280e6-b61c-4591-a530-df7757df3a88"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 16.71 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ww3z6m5LPJ",
        "colab_type": "text"
      },
      "source": [
        "그리고, dataframe으로 파일을 읽고 결측치들을 처리해준다. 본 예제에서는 40%만 샘플링하여서 실험하였다.. 너무 많아서 :("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aBknsOg5KKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('./nsmc/ratings_train.txt', sep='\\t')\n",
        "test_df = pd.read_csv('./nsmc/ratings_test.txt', sep='\\t')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ronnigwl5Os0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.dropna(inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "train_df = train_df.sample(frac=0.4, random_state=999)\n",
        "test_df = test_df.sample(frac=0.4, random_state=999)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4t7XRat5TaU",
        "colab_type": "text"
      },
      "source": [
        "이후 데이터 셋을 만들어주고,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCknEVA-5Rda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NsmcDataset(Dataset):\n",
        "    ''' Naver Sentiment Movie Corpus Dataset '''\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 1]\n",
        "        label = self.df.iloc[idx, 2]\n",
        "        return text, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRY1MdS65Xeo",
        "colab_type": "text"
      },
      "source": [
        "Train에 사용될 DataLoader를 만들어준다. Batch size는 2로 하였는데, 4부터는 Colab의 CUDA 메모리가 터지기 때문이다.. 때문에 굉장히 오래걸리고 NLP가 자원싸움이라는 생각이 많이 들더라."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tefGsk3v5Vdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nsmc_train_dataset = NsmcDataset(train_df)\n",
        "train_loader = DataLoader(nsmc_train_dataset, batch_size=2, shuffle=True, num_workers=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzb8IIQc5dvC",
        "colab_type": "text"
      },
      "source": [
        "이후 과정은 일반적인 LSTM이나 CNN을 사용하는 과정과 동일하다. Huggingface에서 구현된 Bert는 pytorch의 module클래스를 상속받고 있다. 따라서 이미지 분류 classification task처럼 진행해주면 된다.\n",
        "\n",
        "from_pretrained(‘bert-base-multilingual-cased’)를 사용함으로써 google에서 pretrained한 모델을 사용할 수 있다. 그리고 bert 소개글에서와 같이 tokenizer는 wordpiece를 만들어 토큰화가 이루어진다. 여기서 포인트는 우리가 구현체 중 ‘BertForSequenceClassification’모델을 사용하는 것이다. 이 모델은 디폴트로 이진분류가 되어있다. 따라서 multi-label을 하거나 다른 task를 학습하기 위해서는 구현된 다른 서브 모델들을 활용하면 된다. 예컨대, multi-label을 하고 싶으면 기본 BertModel의 classifier layer를 조정해줘야하는데, 이곳을 참고하면 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rScMQgZu5bb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c185ade-6d88-412b-c873-121dc4911e44"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 2286812.35B/s]\n",
            "100%|██████████| 625/625 [00:00<00:00, 346430.55B/s]\n",
            "100%|██████████| 714314041/714314041 [00:24<00:00, 29337713.78B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7kcPMkR5pmg",
        "colab_type": "text"
      },
      "source": [
        "트레이닝 과정은 굉장히 심플하다. optimizer 설정, 일정 주기별로 Loss 찍기 등 흔히 볼 수 있는 코드로 진행이 가능하다. 주의해야하는 것은, 학습 샘플의 인풋이 (batch_size, sequence_length)로 들어간다는 것이다. 따라서 zero-padding을 직접 해줘서 model의 forward에 넣어줘야한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc4nYUtq5mag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbb25f09-def2-4518-90ea-a3e417783568"
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-6)\n",
        "\n",
        "itr = 1\n",
        "p_itr = 500\n",
        "epochs = 1\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    for text, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # encoding and zero padding\n",
        "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "        \n",
        "        sample = torch.tensor(padded_list)\n",
        "        sample, label = sample.to(device), label.to(device)\n",
        "        labels = torch.tensor(label)\n",
        "        outputs = model(sample, labels=labels)\n",
        "        loss, logits = outputs\n",
        "\n",
        "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if itr % p_itr == 0:\n",
        "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
        "            total_loss = 0\n",
        "            total_len = 0\n",
        "            total_correct = 0\n",
        "\n",
        "        itr+=1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1/1] Iteration 500 -> Train Loss: 0.6968, Accuracy: 0.503\n",
            "[Epoch 1/1] Iteration 1000 -> Train Loss: 0.6999, Accuracy: 0.495\n",
            "[Epoch 1/1] Iteration 1500 -> Train Loss: 0.6954, Accuracy: 0.511\n",
            "[Epoch 1/1] Iteration 2000 -> Train Loss: 0.6948, Accuracy: 0.512\n",
            "[Epoch 1/1] Iteration 2500 -> Train Loss: 0.6879, Accuracy: 0.538\n",
            "[Epoch 1/1] Iteration 3000 -> Train Loss: 0.6677, Accuracy: 0.597\n",
            "[Epoch 1/1] Iteration 3500 -> Train Loss: 0.6456, Accuracy: 0.641\n",
            "[Epoch 1/1] Iteration 4000 -> Train Loss: 0.6176, Accuracy: 0.680\n",
            "[Epoch 1/1] Iteration 4500 -> Train Loss: 0.5870, Accuracy: 0.703\n",
            "[Epoch 1/1] Iteration 5000 -> Train Loss: 0.6023, Accuracy: 0.670\n",
            "[Epoch 1/1] Iteration 5500 -> Train Loss: 0.5663, Accuracy: 0.711\n",
            "[Epoch 1/1] Iteration 6000 -> Train Loss: 0.5608, Accuracy: 0.733\n",
            "[Epoch 1/1] Iteration 6500 -> Train Loss: 0.5336, Accuracy: 0.752\n",
            "[Epoch 1/1] Iteration 7000 -> Train Loss: 0.5601, Accuracy: 0.705\n",
            "[Epoch 1/1] Iteration 7500 -> Train Loss: 0.5372, Accuracy: 0.746\n",
            "[Epoch 1/1] Iteration 8000 -> Train Loss: 0.5380, Accuracy: 0.725\n",
            "[Epoch 1/1] Iteration 8500 -> Train Loss: 0.5519, Accuracy: 0.731\n",
            "[Epoch 1/1] Iteration 9000 -> Train Loss: 0.5432, Accuracy: 0.716\n",
            "[Epoch 1/1] Iteration 9500 -> Train Loss: 0.5199, Accuracy: 0.753\n",
            "[Epoch 1/1] Iteration 10000 -> Train Loss: 0.4929, Accuracy: 0.765\n",
            "[Epoch 1/1] Iteration 10500 -> Train Loss: 0.4951, Accuracy: 0.772\n",
            "[Epoch 1/1] Iteration 11000 -> Train Loss: 0.4979, Accuracy: 0.760\n",
            "[Epoch 1/1] Iteration 11500 -> Train Loss: 0.5036, Accuracy: 0.748\n",
            "[Epoch 1/1] Iteration 12000 -> Train Loss: 0.4836, Accuracy: 0.772\n",
            "[Epoch 1/1] Iteration 12500 -> Train Loss: 0.5007, Accuracy: 0.748\n",
            "[Epoch 1/1] Iteration 13000 -> Train Loss: 0.4556, Accuracy: 0.791\n",
            "[Epoch 1/1] Iteration 13500 -> Train Loss: 0.4707, Accuracy: 0.780\n",
            "[Epoch 1/1] Iteration 14000 -> Train Loss: 0.4728, Accuracy: 0.769\n",
            "[Epoch 1/1] Iteration 14500 -> Train Loss: 0.4711, Accuracy: 0.780\n",
            "[Epoch 1/1] Iteration 15000 -> Train Loss: 0.4640, Accuracy: 0.779\n",
            "[Epoch 1/1] Iteration 15500 -> Train Loss: 0.4254, Accuracy: 0.798\n",
            "[Epoch 1/1] Iteration 16000 -> Train Loss: 0.4714, Accuracy: 0.777\n",
            "[Epoch 1/1] Iteration 16500 -> Train Loss: 0.4364, Accuracy: 0.799\n",
            "[Epoch 1/1] Iteration 17000 -> Train Loss: 0.4572, Accuracy: 0.791\n",
            "[Epoch 1/1] Iteration 17500 -> Train Loss: 0.4744, Accuracy: 0.769\n",
            "[Epoch 1/1] Iteration 18000 -> Train Loss: 0.4461, Accuracy: 0.797\n",
            "[Epoch 1/1] Iteration 18500 -> Train Loss: 0.4741, Accuracy: 0.765\n",
            "[Epoch 1/1] Iteration 19000 -> Train Loss: 0.4536, Accuracy: 0.791\n",
            "[Epoch 1/1] Iteration 19500 -> Train Loss: 0.4925, Accuracy: 0.764\n",
            "[Epoch 1/1] Iteration 20000 -> Train Loss: 0.4343, Accuracy: 0.806\n",
            "[Epoch 1/1] Iteration 20500 -> Train Loss: 0.4416, Accuracy: 0.802\n",
            "[Epoch 1/1] Iteration 21000 -> Train Loss: 0.4207, Accuracy: 0.809\n",
            "[Epoch 1/1] Iteration 21500 -> Train Loss: 0.4771, Accuracy: 0.773\n",
            "[Epoch 1/1] Iteration 22000 -> Train Loss: 0.4348, Accuracy: 0.794\n",
            "[Epoch 1/1] Iteration 22500 -> Train Loss: 0.4474, Accuracy: 0.790\n",
            "[Epoch 1/1] Iteration 23000 -> Train Loss: 0.4420, Accuracy: 0.789\n",
            "[Epoch 1/1] Iteration 23500 -> Train Loss: 0.4468, Accuracy: 0.787\n",
            "[Epoch 1/1] Iteration 24000 -> Train Loss: 0.4540, Accuracy: 0.775\n",
            "[Epoch 1/1] Iteration 24500 -> Train Loss: 0.4330, Accuracy: 0.793\n",
            "[Epoch 1/1] Iteration 25000 -> Train Loss: 0.4041, Accuracy: 0.814\n",
            "[Epoch 1/1] Iteration 25500 -> Train Loss: 0.4190, Accuracy: 0.795\n",
            "[Epoch 1/1] Iteration 26000 -> Train Loss: 0.4558, Accuracy: 0.773\n",
            "[Epoch 1/1] Iteration 26500 -> Train Loss: 0.4288, Accuracy: 0.802\n",
            "[Epoch 1/1] Iteration 27000 -> Train Loss: 0.4169, Accuracy: 0.808\n",
            "[Epoch 1/1] Iteration 27500 -> Train Loss: 0.4112, Accuracy: 0.815\n",
            "[Epoch 1/1] Iteration 28000 -> Train Loss: 0.4118, Accuracy: 0.817\n",
            "[Epoch 1/1] Iteration 28500 -> Train Loss: 0.4357, Accuracy: 0.789\n",
            "[Epoch 1/1] Iteration 29000 -> Train Loss: 0.4398, Accuracy: 0.809\n",
            "[Epoch 1/1] Iteration 29500 -> Train Loss: 0.3998, Accuracy: 0.812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cQu7ozG8LR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "0bceb30e-7229-4341-a133-f4c0c35d9baa"
      },
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "\n",
        "nsmc_eval_dataset = NsmcDataset(test_df)\n",
        "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
        "\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "for text, label in eval_loader:\n",
        "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "    sample = torch.tensor(padded_list)\n",
        "    sample, label = sample.to(device), label.to(device)\n",
        "    labels = torch.tensor(label)\n",
        "    outputs = model(sample, labels=labels)\n",
        "    _, logits = outputs\n",
        "\n",
        "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "    correct = pred.eq(labels)\n",
        "    total_correct += correct.sum().item()\n",
        "    total_len += len(labels)\n",
        "\n",
        "print('Test accuracy: ', total_correct / total_len)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.8132406620331016\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}